{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n"
      ],
      "metadata": {
        "id": "HIRmfmeWnOiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir drive/MyDrive/poet_params -p"
      ],
      "metadata": {
        "id": "VJv0EwicnTWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp drive/MyDrive/datasets/poems.zip datasets.zip\n",
        "!cp drive/MyDrive/poet_params/TRL_2.8219_TSL_3.1686_EMB_768_LYR_5_HDS_16_CTX_128_LR_0.0001.pth ."
      ],
      "metadata": {
        "id": "ZSzw2pQfmG-D"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5AGUOI1L5KD8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import platform\n",
        "\n",
        "if not os.path.exists(\"./datasets.zip\"):\n",
        "    print(\"upload datasets\")\n",
        "elif platform.system() == \"Windows\":\n",
        "    os.system(\"git clone https://github.com/n1teshy/poet & move poet/tokenizer . & move poet/core . & rd /s /q poet\")\n",
        "    os.system(\"powershell Expand-Archive -Path ./datasets -DestinationPath .\")\n",
        "else:\n",
        "    os.system(\"git clone https://github.com/n1teshy/poet && mv poet/tokenizer . && mv poet/core . && rm -rf poet\")\n",
        "    os.system(\"unzip ./datasets -d .\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8odFqXR_5KD-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import AdamW\n",
        "from core.tokenizers.regex import get_tokenizer\n",
        "from core.utils import get_param_count\n",
        "from core.config import device\n",
        "from core.models import Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "AUO5S6T25KD_"
      },
      "outputs": [],
      "source": [
        "BLOCK_SIZE = 128\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 10\n",
        "EMBEDDING_SIZE = 768\n",
        "LAYERS = 5\n",
        "HEADS = 16\n",
        "TRAIN_FILE = \"datasets/train.txt\"\n",
        "TEST_FILE = \"datasets/test.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "CUOXqa8W5KD_"
      },
      "outputs": [],
      "source": [
        "tokenizer = get_tokenizer(\"poems.txt\", 1024, \"tokenizer/en\", True)\n",
        "train_data = tokenizer.encode(open(TRAIN_FILE, encoding=\"utf-8\").read())\n",
        "test_data = tokenizer.encode(open(TEST_FILE, encoding=\"utf-8\").read())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "U7GLaFCA5KD_"
      },
      "outputs": [],
      "source": [
        "def get_batch(split):\n",
        "    data = train_data if split == \"train\" else test_data\n",
        "    idxs = torch.randint(len(data) - BLOCK_SIZE, (BATCH_SIZE, ))\n",
        "    X = [data[idx: idx + BLOCK_SIZE] for idx in idxs]\n",
        "    Y = [data[idx + 1: idx + 1 + BLOCK_SIZE] for idx in idxs]\n",
        "    return torch.tensor(X, device=device), torch.tensor(Y, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRt7eZdw5KD_"
      },
      "outputs": [],
      "source": [
        "model_checkpoint = \"TRL_2.8219_TSL_3.1686_EMB_768_LYR_5_HDS_16_CTX_128_LR_0.0001.pth\"\n",
        "model = Generator(tokenizer.size, EMBEDDING_SIZE, BLOCK_SIZE, LAYERS, HEADS).to(device)\n",
        "model.load_state_dict(torch.load(model_checkpoint))\n",
        "print(\"%.4f mn parameters\" % (get_param_count(model) / 1e6, ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "G0ybUS9_5KEA"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def get_test_loss():\n",
        "    model.eval()\n",
        "    inp, tgt = get_batch(\"test\")\n",
        "    logits = model(inp)\n",
        "    B, T, C = logits.shape\n",
        "    logits, tgt = logits.reshape(B*T, C), tgt.reshape(B*T)\n",
        "    loss = F.cross_entropy(logits, tgt)\n",
        "    model.train()\n",
        "    return loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "VAMmZ4gv5KEA"
      },
      "outputs": [],
      "source": [
        "def batch_generator(split):\n",
        "    while True:\n",
        "        yield get_batch(split)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "pPQxuMFA5KEA"
      },
      "outputs": [],
      "source": [
        "LEARNING_RATE = 0.0001\n",
        "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "1-1VY8BC5KEA"
      },
      "outputs": [],
      "source": [
        "mean_train_loss, mean_test_loss = 2.83, 0\n",
        "batch_to_epoch = len(train_data) / BATCH_SIZE\n",
        "last_saved_train_loss = 2.8219"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model(folder):\n",
        "    model_id = \"TRL_%.4f_TSL_%.4f_EMB_%d_LYR_%d_HDS_%d_CTX_%d_LR_%.4f\" % (\n",
        "        mean_train_loss,\n",
        "        mean_test_loss,\n",
        "        EMBEDDING_SIZE,\n",
        "        LAYERS,\n",
        "        HEADS,\n",
        "        BLOCK_SIZE,\n",
        "        LEARNING_RATE,\n",
        "    )\n",
        "    torch.save(model.state_dict(), os.path.join(folder, f\"{model_id}.pth\"))\n"
      ],
      "metadata": {
        "id": "YQt-BiykOlFM"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EN7Y1tte5KEA"
      },
      "outputs": [],
      "source": [
        "for batch_no, (inp, tgt) in enumerate(batch_generator(\"train\"), start=1):\n",
        "    optimizer.zero_grad()\n",
        "    logits = model(inp)\n",
        "    B, T, C = logits.shape\n",
        "    logits, tgt = logits.reshape(B * T, C), tgt.reshape(B * T)\n",
        "    train_loss = F.cross_entropy(logits, tgt)\n",
        "    train_loss.backward()\n",
        "    optimizer.step()\n",
        "    test_loss = get_test_loss()\n",
        "    train_loss, test_loss = train_loss.item(), test_loss.item()\n",
        "    mean_train_loss = (mean_train_loss or train_loss) * 0.9975 + train_loss * 0.0025\n",
        "    mean_test_loss = (mean_test_loss or test_loss) * 0.9975 + test_loss * 0.0025\n",
        "    print(\n",
        "        \"%d:%d -> (%.4f | %.4f), (%.4f | %.4f)\"\n",
        "        % (\n",
        "            batch_no // batch_to_epoch + 1,\n",
        "            batch_no % batch_to_epoch,\n",
        "            train_loss,\n",
        "            mean_train_loss,\n",
        "            test_loss,\n",
        "            mean_test_loss,\n",
        "        )\n",
        "    )\n",
        "    if last_saved_train_loss - mean_train_loss >= 0.02:\n",
        "      save_model(\"drive/MyDrive/poet_params\")\n",
        "      print(f\"saved model at train loss {mean_train_loss}\")\n",
        "      last_saved_train_loss = mean_train_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(text=\" \", max_len=400):\n",
        "  context = torch.tensor([tokenizer.encode(text)], device=device)\n",
        "  output = []\n",
        "  for _ in range(max_len):\n",
        "    logits = model(context)\n",
        "    probs = F.softmax(logits, dim=-1)\n",
        "    probs = probs[:, -1:, :].view(-1, tokenizer.size)\n",
        "    next_token = torch.multinomial(probs, num_samples=1)\n",
        "    print(tokenizer.decode([next_token.item()]), end=\"\")\n",
        "    context = torch.cat((context, next_token), dim=1)[:, -BLOCK_SIZE:]\n",
        "  return output\n",
        "\n",
        "generate(text=\"women\")"
      ],
      "metadata": {
        "id": "vrPFL_Q9vuaI",
        "outputId": "01ef1c6a-a8fd-4312-ffea-252e3f95b0bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'s laws belonged,\n",
            "The proud hearts of battle,\n",
            "Bully theirs before them fell away,\n",
            "From their Earth, thus the blestless singer,\n",
            "Foster of that golden monarch!\n",
            "Later all were being one and all men,\n",
            "With human heart affording wives,\n",
            "To make the people judgingly ride,\n",
            "And their deep retainments. Let them go\n",
            "With sable dusted step amazed\n",
            "Their strides shine on music and song;\n",
            "And all its plings are stubble and thing,\n",
            "And the rich recordance of her head;\n",
            "And which they sink, as lovely as wine\n",
            "Where they daily creep:\n",
            "And life shall bring to her lovers and their rests,\n",
            "And the sea-born willows that have waited.\n",
            "Therefore gracious in fairest secrets shall\n",
            "Shall read Hero's praise the lands where love,\n",
            "And bright reign'st away shall Virtues keep,\n",
            "And thy quarren leaves each other joy, and warmme;\n",
            "The outward make thee beneath the winding pool\n",
            "Bloodry bees of silver and loud;\n",
            "Then, send her fortune in the gloom, and crowed,\n",
            "Rising in the moons of Mushell to the town.\n",
            "Then thou wouldst rude proudent seem\n",
            "That pants ,  consciousness, and c"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}